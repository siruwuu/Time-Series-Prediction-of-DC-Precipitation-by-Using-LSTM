{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import xarray as xr\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:07:19,486 WARNING [2024-11-27T00:00:00] System is back on service under testing conditions. Please follow updates [here](https://forum.ecmwf.int/t/cds-ads-and-ewds-down-until-further-notice/8015) and status [here](https://status.ecmwf.int/)\n",
      "2024-12-02 21:07:19,488 INFO [2024-09-28T00:00:00] **Welcome to the New Climate Data Store (CDS)!** This new system is in its early days of full operations and still undergoing enhancements and fine tuning. Some disruptions are to be expected. Your \n",
      "[feedback](https://jira.ecmwf.int/plugins/servlet/desk/portal/1/create/202) is key to improve the user experience on the new CDS for the benefit of everyone. Thank you.\n",
      "2024-12-02 21:07:19,489 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n",
      "2024-12-02 21:07:19,490 INFO [2024-09-16T00:00:00] Remember that you need to have an ECMWF account to use the new CDS. **Your old CDS credentials will not work in new CDS!**\n",
      "2024-12-02 21:07:19,491 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data for month 01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:07:20,139 INFO Request ID is c0382a0d-c430-427f-932e-f69022791beb\n",
      "2024-12-02 21:07:20,527 INFO status has been updated to accepted\n",
      "2024-12-02 21:07:25,135 INFO status has been updated to running\n",
      "2024-12-02 21:09:12,385 INFO status has been updated to successful\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 01 saved to DC_Month_Data/dc_weather_2024_month_01.nc.\n",
      "Downloading data for month 02...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:09:15,019 INFO Request ID is c576fbd9-8b14-4b49-80b1-4778bd89dfea\n",
      "2024-12-02 21:09:15,225 INFO status has been updated to accepted\n",
      "2024-12-02 21:09:24,309 INFO status has been updated to running\n",
      "2024-12-02 21:11:08,258 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 02 saved to DC_Month_Data/dc_weather_2024_month_02.nc.\n",
      "Downloading data for month 03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:11:11,425 INFO Request ID is db3eedfb-e306-444e-b3d2-1d015ce71365\n",
      "2024-12-02 21:11:11,574 INFO status has been updated to accepted\n",
      "2024-12-02 21:11:18,450 INFO status has been updated to running\n",
      "2024-12-02 21:13:05,405 INFO status has been updated to successful\n",
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 03 saved to DC_Month_Data/dc_weather_2024_month_03.nc.\n",
      "Downloading data for month 04...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:13:07,300 INFO Request ID is 28122057-1ae3-48fa-a3f6-4997282bdd02\n",
      "2024-12-02 21:13:07,458 INFO status has been updated to accepted\n",
      "2024-12-02 21:13:13,074 INFO status has been updated to running\n",
      "2024-12-02 21:15:02,094 INFO status has been updated to successful\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 04 saved to DC_Month_Data/dc_weather_2024_month_04.nc.\n",
      "Downloading data for month 05...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:15:05,103 INFO Request ID is 8fd5fe60-e5bc-4675-a3b6-f619b17f44a5\n",
      "2024-12-02 21:15:05,311 INFO status has been updated to accepted\n",
      "2024-12-02 21:15:08,887 INFO status has been updated to running\n",
      "2024-12-02 21:16:58,319 INFO status has been updated to successful\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 05 saved to DC_Month_Data/dc_weather_2024_month_05.nc.\n",
      "Downloading data for month 06...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:17:02,041 INFO Request ID is f1451250-1a8c-4e7d-bc09-317c4958bd81\n",
      "2024-12-02 21:17:02,241 INFO status has been updated to accepted\n",
      "2024-12-02 21:17:11,283 INFO status has been updated to running\n",
      "2024-12-02 21:18:18,224 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 06 saved to DC_Month_Data/dc_weather_2024_month_06.nc.\n",
      "Downloading data for month 07...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:18:20,309 INFO Request ID is 45ac23a6-5535-4228-8fc3-90f469ceda3a\n",
      "2024-12-02 21:18:20,520 INFO status has been updated to accepted\n",
      "2024-12-02 21:18:26,058 INFO status has been updated to running\n",
      "2024-12-02 21:21:09,372 INFO status has been updated to successful\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 07 saved to DC_Month_Data/dc_weather_2024_month_07.nc.\n",
      "Downloading data for month 08...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:21:12,412 INFO Request ID is 331502d4-e378-405f-9660-b2950ca0096c\n",
      "2024-12-02 21:21:12,557 INFO status has been updated to accepted\n",
      "2024-12-02 21:21:18,099 INFO status has been updated to running\n",
      "2024-12-02 21:24:00,414 INFO status has been updated to successful\n",
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 08 saved to DC_Month_Data/dc_weather_2024_month_08.nc.\n",
      "Downloading data for month 09...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:24:02,957 INFO Request ID is fabbea1d-20ec-429a-a645-a35b5bcd4242\n",
      "2024-12-02 21:24:03,193 INFO status has been updated to accepted\n",
      "2024-12-02 21:24:08,707 INFO status has been updated to running\n",
      "2024-12-02 21:26:51,450 INFO status has been updated to successful\n",
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 09 saved to DC_Month_Data/dc_weather_2024_month_09.nc.\n",
      "Downloading data for month 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:26:53,473 INFO Request ID is 3a6e4db1-ad7d-4379-8807-616081808947\n",
      "2024-12-02 21:26:53,627 INFO status has been updated to accepted\n",
      "2024-12-02 21:26:58,941 INFO status has been updated to running\n",
      "2024-12-02 21:31:07,292 WARNING Structural differences in grib fields detected when opening in xarray. Opening the grib file safely, however this may result in files with non-intuitive filenames.\n",
      "2024-12-02 21:31:07,293 INFO status has been updated to successful\n",
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 10 saved to DC_Month_Data/dc_weather_2024_month_10.nc.\n",
      "Downloading data for month 11...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 21:31:09,947 INFO Request ID is cb9f5354-fb4c-4ab6-980f-afe8ee7a51d9\n",
      "2024-12-02 21:31:10,278 INFO status has been updated to accepted\n",
      "2024-12-02 21:31:15,065 INFO status has been updated to running\n",
      "2024-12-02 21:37:18,250 INFO status has been updated to successful\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for month 11 saved to DC_Month_Data/dc_weather_2024_month_11.nc.\n",
      "Merging all monthly NetCDF files into a single dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Merge all files into a single dataset\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerging all monthly NetCDF files into a single dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 64\u001b[0m combined_ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mby_coords\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Save the merged dataset\u001b[39;00m\n\u001b[1;32m     67\u001b[0m combined_ds\u001b[38;5;241m.\u001b[39mto_netcdf(combined_output_path)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/api.py:1579\u001b[0m, in \u001b[0;36mopen_mfdataset\u001b[0;34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[0m\n\u001b[1;32m   1576\u001b[0m     open_ \u001b[38;5;241m=\u001b[39m open_dataset\n\u001b[1;32m   1577\u001b[0m     getattr_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m\n\u001b[0;32m-> 1579\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[43mopen_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths1d]\n\u001b[1;32m   1580\u001b[0m closers \u001b[38;5;241m=\u001b[39m [getattr_(ds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_close\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m ds \u001b[38;5;129;01min\u001b[39;00m datasets]\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/api.py:651\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 651\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    654\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/venv/lib/python3.12/site-packages/xarray/backends/plugins.py:194\u001b[0m, in \u001b[0;36mguess_engine\u001b[0;34m(store_spec)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m     )\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: did not find a match in any of xarray's currently installed IO backends ['netcdf4', 'h5netcdf', 'scipy']. Consider explicitly selecting one of the installed engines via the ``engine`` parameter, or installing additional IO dependencies, see:\nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\nhttps://docs.xarray.dev/en/stable/user-guide/io.html"
     ]
    }
   ],
   "source": [
    "# Initialize CDS API client\n",
    "client = cdsapi.Client()\n",
    "\n",
    "# Dataset name\n",
    "dataset = \"reanalysis-era5-land\"\n",
    "\n",
    "# Variables: Add more related variables\n",
    "variables = [\n",
    "    \"total_precipitation\",  # Total Precipitation (m)\n",
    "    \"2m_temperature\",       # 2m Temperature (K)\n",
    "    \"surface_solar_radiation_downwards\",  # Surface solar radiation downwards (J/m^2)\n",
    "    \"soil_temperature_level_1\",  # Soil temperature level 1 (K)\n",
    "]\n",
    "\n",
    "# Define a small geographic area for the Capitol region (DC)\n",
    "dc_extent = {\n",
    "    \"area\": [38.8977, -77.0365, 38.8975, -77.0363],  # [North Latitude, West Longitude, South Latitude, East Longitude]\n",
    "}\n",
    "\n",
    "# Time resolution: 4 hours\n",
    "time_intervals = [\n",
    "    \"00:00\", \"06:00\", \"12:00\", \"18:00\"\n",
    "]\n",
    "\n",
    "# Output directory for monthly data\n",
    "output_dir = \"DC_Month_Data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Download data for each month from January to November\n",
    "for month in range(1, 12):\n",
    "    print(f\"Downloading data for month {month:02d}...\")\n",
    "\n",
    "    # Request parameters\n",
    "    request = {\n",
    "        \"format\": \"netcdf\",\n",
    "        \"product_type\": \"reanalysis\",\n",
    "        \"variable\": variables,\n",
    "        \"year\": \"2024\",\n",
    "        \"month\": f\"{month:02d}\",\n",
    "        \"day\": [f\"{day:02d}\" for day in range(1, 32)],  # Days in the month\n",
    "        \"time\": time_intervals,\n",
    "        **dc_extent,  # Add geographic range\n",
    "    }\n",
    "\n",
    "    # Output file path for each month\n",
    "    output_filename = os.path.join(output_dir, f\"dc_weather_2024_month_{month:02d}.nc\")\n",
    "\n",
    "    # Perform data retrieval\n",
    "    client.retrieve(dataset, request, output_filename)\n",
    "    print(f\"Data for month {month:02d} saved to {output_filename}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully saved to data/DC_combined_precipitation_2024.csv\n"
     ]
    }
   ],
   "source": [
    "nc_file_path = \"DC_combined_precipitation_2024.nc\"\n",
    "output_csv_path = \"data/DC_combined_precipitation_2024.csv\"\n",
    "\n",
    "ds = xr.open_dataset(nc_file_path)\n",
    "\n",
    "df = ds.to_dataframe().reset_index()\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Data has been successfully saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data has been successfully saved to data/DC_combined_precipitation_2024_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "nc_file_path = \"DC_combined_precipitation_2024.nc\"\n",
    "output_csv_path = \"data/DC_combined_precipitation_2024_cleaned.csv\"\n",
    "\n",
    "ds = xr.open_dataset(nc_file_path)\n",
    "\n",
    "df = ds.to_dataframe().reset_index()\n",
    "\n",
    "columns_to_drop = [\"latitude\", \"longitude\", \"number\", \"expver\"]\n",
    "df = df.drop(columns=columns_to_drop, errors=\"ignore\")\n",
    "\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data has been successfully saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to data/processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "file_path = \"data/DC_combined_precipitation_2024_cleaned.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define the columns that need to be standardized\n",
    "columns_to_scale = [\"tp\", \"t2m\", \"ssrd\", \"stl1\"]\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "data[columns_to_scale] = scaler.fit_transform(data[columns_to_scale])\n",
    "\n",
    "processed_file_path = \"data/processed_data.csv\"\n",
    "data.to_csv(processed_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data saved to {processed_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
